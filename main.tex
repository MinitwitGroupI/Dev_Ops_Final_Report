\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{biblatex} % Bibliography package
\addbibresource{bibliography.bib} % Bibliography file

% For counting words
\usepackage{verbatim}
\newcommand\wordcount{
  \immediate\write18{texcount -1 -sum -merge -q main.tex > main.wcdetail }%
  \verbatiminput{main.wcdetail}%
}


\title{DevOps - Final Report\\
  \large Group I
}
\author{
Anders Latif (alat@itu.dk)\\
Ivar Cmreƒçak (ivcm@itu.dk)\\
Mads Meinert Andersen (mmea@itu.dk) \\
Mikkel Rahlff Berggreen (mirb@itu.dk)\\ 
Nedas Surkus (nesu@itu.dk)\\
}
\date{May 2023}


\begin{document}

\maketitle

\vspace*{\fill}
Word count: 
\wordcount


\pagebreak

\tableofcontents
\pagebreak

\section{Problem formulation}

We have inherited a legacy system called Minitwit and have been tasked with refactoring it. Besides modernizing the stack it has been our aim to do so using DevOps methodologies. By reflecting on select few pillars of DevOps the final question becomes whether or not we achieved this goal. Is what we've done DevOps?

\section{System's Perspective} 

\subsection{Design and architecture of the system}

Minitwit uses a container-based architecture where each service runs in its own Docker container. The backend is built with FastAPI and Jinja. Grafana and Prometheus are utilized for monitoring, the EFK stack for logging, Redis\footnote{Redis is only used to store the number of total http calls since FastAPI is a multi-threaded server that doesn't allow for global state} and PostgreSQL serve as database.

The deployment view below is to help illustrate how these components are deployed and interact with each other in a production environment, see figure \ref{fig:deployment_view}. 

\begin{figure}[h]
\includegraphics[width=1\textwidth]{images/Deployment_View_Picture.png}
\label{fig:deployment_view}
\caption{Minitwit deployment view}
\centering
\end{figure}
\newpage
\subsection{Dependencies of the system (Mikkel)}

\begin{figure}[h]
\includegraphics[width=0.9\textwidth]{images/Technologies and tools.jpg}
\centering
\end{figure}

% Technologies and tools:
% \begin{itemize}
%     \item FastAPI for the backend.
%     \item PostgreSQL as database system.
%     \item SQLAlchemy as an ORM framework.
%     \item Docker for containerization.
%     \item Vagrant for managing creation of virtual environments.
%     \item DigitalOcean for hosting virtual environments on a remote server.
%     \item GitHub Actions and Ansible for the CI/CD chain.
%     \item Prometheus and Grafana for monitoring and visualising the state of the system.
%     \item Postman for testing of the API.
%     \item Elasticsearch, Filebeat and Kibana as a logging stack.
%     \item Redis for storing global state.
%     \item Nginx and Heartbeat for a high-availablity setup with a staging and deployment server.
%     \item Certbot for adding HTTPS to the website.
% \end{itemize}

% Languages:
% \begin{itemize}
%     \item Python for the web application.
%     \item Jinja as a templating language.
%     \item Dockerfile.
%     \item YAML for Docker, Ansible and Github Actions
% \end{itemize}

\subsection{Subsystem interactions}

\subsection{State of the system (Mikkel)}

The application is accessible on \url{opsdev.gg}. The code can be found in \href{https://github.com/MinitwitGroupI/MiniTwit}{this repository}. Everything is running without error and will be accessible until the date TODO.
Our system has been able to process XXXX \footnote{SOURCE TODO} amount of events in the span of XXXX TODO weeks.

\subsection{Licences}

Since profiteering is not our purpose the code is under the \href{https://github.com/MinitwitGroupI/MiniTwit/blob/main/LICENSE}{MIT License}.

\subsection{Weekly tasks (All) }


\subsubsection{Week 1 - Bug fixing the old program}

By importing the project to IntelliJ it auto-suggested to update the Python version from 2 to 3. We used shellcheck to lint the bash script.

\subsubsection{Week 2 - Refactoring the app in another language }

We listed possible frameworks, voted to exclude and then used a roulette to pick between two. The process is described here \footnote{\url{https://docs.google.com/document/d/1EOrFKD0XFW5gxv1NycgtTuj9rO6dggau99LybLYIRq0/edit\#heading=h.r8lyr8ciz36h }}. 

The arguments for FastAPI is how we could reuse the existing python code base and even reuse Jinja. Besides the ease of refactoring it was also familiar to some of us. 

We experienced some unexpected downsides:
\begin{itemize}

    \item The implementation of redirection for instance redirecting from a POST to another POST request would mean the loss of the original body and no way to pass it along. 
    \item Redirecting between different routes that return different status codes was also an unexpected challenge. 
    \item Since it is multi-threaded server it excludes the ability to have a global state and a session. We solved it with Starlette Session.
    \item The tests required to be translated to "pytest" framework in order to be utilised.
\end{itemize}

\subsubsection{Week 3 - Virtualisation and deployment to the server}

A new Docker feature called Dev Environments which gave us feature errors with mounting from files to containers and hot reloading .  

\subsubsection{Week 4 - Setting up CI/CD system }

Github Actions gave us a simple configuration process without needing additional hosted infrastructure. See section \ref{cicd}. 

\subsubsection{Week 5 - ORM }

Three ORMs have been considered and the arguments are mapped \footnote{\url{https://docs.google.com/document/d/1EOrFKD0XFW5gxv1NycgtTuj9rO6dggau99LybLYIRq0/edit\#heading=h.auxry4rgtrx1}}. A benchmarks repository was created \footnote{\url{https://github.com/MinitwitGroupI/ORM_Benchmarks }} and after a Github Discussion \footnote{\url{https://github.com/MinitwitGroupI/MiniTwit/discussions/57 }} a vote was held. The choice fell on the most popular choice for Python - SQLAlchemy - and it did not cause regret. 

\subsubsection{Week 6 - Monitoring }

Prometheus with Grafana is considered the most popular choice in the industry \footnote{https://stackshare.io/stackups/grafana-vs-nagios}. 

We checked our partner groups website and created issues for known issues \footnote{\url{https://github.com/organizationGB/DevOps/issues/23}} \footnote{\url{https://github.com/organizationGB/DevOps/issues/25}}. 


\subsubsection{Week 7 - Maintainability, external code analysing }

The Flake8 linter that pylint uses does static code analysis in our CI pipeline to provide soft feedback that does not block builds but hint at potential problems. SonarQube and CodeClimate integrated perfectly with our repository but gave vastly different views on code quality than us. It required manually dismissing a lot of warnings about duplicated code which existed in our unit tests. It ended up being a burden rather than helpful.

\subsubsection{Week 8 - EFK stack}

Significant issues were encountered when setting up the EFK stack:

\begin{itemize}
    \item Poor support for creating custom user credentials for WHAT?.
    \item User credentials on Filebeat had to be manually hard coded.
    \item With regards to security it was difficult to enable for each service and could only be tested in production given our setup. 
    \item Adjustment of versions were required from the provided guide. 
\end{itemize}

Postmortem exercises was completed. A bug was introduced an it was discovered with the help of logging. link?

\subsubsection{Week 9 - Security  assessment}

Metasploit and OWASP ZAP scans revealed minor vulnerabilities in the frontend. WHAT WERE THEY???

The idea of integrating OWASP ZAP to the CI/CD pipeline was considered but dismissed on grounds of being beyond the scope.

A security assessment was performed on our partner group \label{appendix:security assessment}. 


\subsubsection{Week 10 - Scaling and rolling out updates }

We opted to go with the high-availability setup, since using a scalable deployment would require refactoring several components of our stack.

We already implemented deployments to a staging environment prior to production, so adding the staging server to our high-availability setup also provided us with rolling updates.  

\subsubsection{Week 12 - Encode your infrastructure setup }

Changing our existing IaC from Vagrant to Terraform did not provide any perceived benefits. Vagrant works for both provisioning and configuration management. Besides the lack of benefits the downside of Terraform is having to deal with state. 

\section{Process' perspective} \label{cicd}

\subsection{Team Organisation and Developer interaction (Ivar)} 

Since creating the Github organisation \href{https://github.com/MinitwitGroupI/}{MinitwitGroupI} team interaction was centered around Github and Discord. Discord was used for informal chatter and to contact each other. For tasks and discussions Github issues were used. This gave us a Project View with a visual Kanban \footnote{\url{https://github.com/orgs/MinitwitGroupI/projects/1}}. A higher use of Github as a communication platform was observed as time progressed. 

We strived to ensure that everyone worked on every aspect of the project, promoting a well-rounded understanding of each component. However, certain sections of the project were more esoteric and hacky, making it challenging for everyone to fully grasp the intricacies of every component. 


\subsection{Stages and tools utilized in CI/CD chains (Ivar)}

Github Actions seamlessly integrated with our codebase. This integration enables us to easily automate the process of building, testing and deploying our application with every commit on every pull request.

\subsubsection{Continuous Integration (CI)}

Upon each commit, Github Actions triggers a job that builds our application using Docker. This process creates a Docker image, which is then used as the environment for running our custom unit and integration tests.

For a pull request to be merged, it must successfully pass all unit and integration tests.

\subsubsection{Continuous Deployment (CD)}

Once a pull request has been merged with our main branch, our CD pipeline is automatically triggered. 
The first step in this pipeline is pushing the new versions our custom Docker images to our image repository. 

Using Ansible, we first deploy our entire application stack to a staging server. This environment allows us to verify the functionality and stability of our application before deploying it to production.

After successful deployment to the staging server, we run liveness tests using Postman. These tests are designed to validate the overall health and performance of our application, ensuring that it meets the necessary requirements for production deployment.

A passing liveness test is required to deploy to our production server. 

\subsection{Organization of the repository}

\url{https://github.com/MinitwitGroupI/MiniTwit/blob/main/docs/CONTRIBUTE.md}
That is, either the structure of of mono-repository or organization of artifacts across repositories.
In essence, it has to be be clear what is stored where and why.

\textcolor{red}{this is already mostly explained in our CONTRIBUTE.md file}

\subsection{Branching strategy (Anders)}

We use the feature branches strategy for individual development. For releases \footnote{https://github.com/MinitwitGroupI/MiniTwit/releases} we achieved trunk based development by pushing into main and manually bundling a release. In order to push to main we had setup branch protection that require pull requests to be reviewed by at least one other team members\footnote{Initially two members were required to review it but we found it stifling to development and change it to one.}. Our branching philosophy is described here \footnote{https://github.com/MinitwitGroupI/MiniTwit/blob/main/docs/CONTRIBUTE.md}.

\subsection{Monitoring (Mads)}
We use Grafana and Prometheus to gather and visualize data on various aspects of our system, including endpoint hits, response times, total number of requests, CPU usage, and request duration distribution. These metrics are displayed across five different panels that provide a comprehensive overview of our system's performance. By monitoring these key metrics, we can quickly identify any issues that may arise and take action to ensure that our system is running smoothly and efficiently. You can find the dashboard here\footnote{\url{http://opsdev.gg:3000/d/DVJQxp-4k/minitwit-responses?orgId=1&from=now-24h&to=now}}.

todo: Explain why we find the metrics to be of interest.

\subsection{Logging (Anders)}

For logging we use the EFK stack. The Elasticsearch dashboard can be found on \url{http://opsdev.gg:5601} with the username helgeandmircea and password sesame0uvr3toi.

\subsection{Security Assessment}

\begin{itemize}
    \item All attacks with Metasploit and OWASP ZAP failed to produce any significant results on our website. 
    \item The peer team  attempted to exploit the website but also did not produce any note worthy results. 
    \item Reviewing the peer team resulted in the other teams database and cookies being compromised. We go into depth in the appendix \label{appendix:security assessment}.

\end{itemize}


 

\subsection{Scaling and Load balancing (Anders)}

We have opted out of a scalable setup since this would require us to heavily refactor our infrastructure and separate our database from individual nodes. This would cost more with no added benefit in the confinement of the expected user growth before the deadline.  

\subsection{High-availability setup (Anders)}

We have opted for a high-available setup by using heartbeat using a guide provided by DigitalOcean \footnote{https://www.digitalocean.com/community/tutorials/how-to-create-a-high-availability-setup-with-heartbeat-and-reserved-ips-on-ubuntu-16-04}. This utilizes `floatip` which uses the DigitalOcean API to update the reserved IP to point at the other server when one is unavailable. 

????


\section{DevOps principles}

\subsection{What is DevOps}

Going by the DevOps Handbook \cite{devopshandbook} we have chosen a couple defining concepts to compare our result against. 

Todo: DevOps principles and how much we adhered to them (and how).

The categories are from here:
\url{https://github.com/itu-devops/lecture_notes/blob/master/sessions/session_05/README_TASKS.md}

\subsubsection{Flow}

Make work visible
Limit Work in Progress
Reduce Batch Sizes
Sometimes it was not possible to create small batch commits. The limitation being 

    Reduce the Number of Handoffs
    Continually Identify and Evaluate Constraints
    Eliminate Hardships and Waste in the Value Stream



\subsubsection{Feedback}

    See Problems as They Occur
    Swarm and Solve Problems to Build New Knowledge
    Keep Pushing Quality Closer to the Source
    Enable Optimizing for Downstream Work Centers


\subsubsection{Continual Learning and experimentation}

    Institutionalize the Improvement of Daily Work
    Transform Local Discoveries into Global Improvements
    Inject Resilience Patterns into Our Daily Work
    Leaders Reinforce a Learning Culture


\subsection{Another view - DevOps as a culture}

DevOps has enjoyed many different views through different eras \cite{devopsviewsthrougheras}. The supplemental book, The Phoenix Project \cite{thephoenixproject} and the guest lecture by Zander Havgaard from Eficode provides a fresh perspective of DevOps as a culture. 


Psychological safety: (Explain how we were at odds in the beginning when selecting a framework). 

"The Bus Factor" was repeated during the guest lecture which is the concept that no single developer should become key to development or infrastructure to the degree that progress can't occur without them. We failed in this regard. We each carved out our niche based on previous knowledge. While PR reviews occurred there was insufficient knowledge sharing for role shifting. 

\subsubsection{Ways we are not DevOps}

We don't follow the Toyota Kata. 

TDD... We could've written more code tests. Though with Postman we were able to test the availability of our infrastructure before deploying. Reflection: This seems like the typical case of tests being on the cutting block when time is scarce. 


\section{Lessons Learned Perspective}

\subsection{Issues and lessons learned (All)}


\subsubsection{Refactoring} 

Refactoring was a breeze because we choose FastAPI which allowed us to reuse big parts of the original Flask application. While Flask would've sufficed we managed to add better security through password encryption in our refactoring. 

\subsubsection{Evolution}

We were often blocked by upcoming tasks. We were waiting for the ORM task to finish so that we could create database migrations. We also anticipated the lecture about infrastructure as code since it would solve ????.

\subsubsection{Maintenance (Anders)}

Thanks to our monitor dashboards and Postman monitors we picked up on some infrequent outages. We could not verify whether some were caused by the simulator pausing or a problem on our end. We experienced at least three types of known outages:

\begin{enumerate}
    \item Outage during deployment while the Docker image was pulled and started. This was solved by our high-availability setup. 
    \item Didn't we experience some outages that were caused by the high-availability setup being misconfigured?
    \item The daily 5 AM outage. Through research we discovered that PostgreSQL by default restarts and does garbage collection and other maintanance. 
\end{enumerate}

Overall we felt that a minimal amount of maintenance is needed and would confidently hand over the project to another team. 

\subsection{Uptime}

The metrics in our SLA\footnote{https://github.com/MinitwitGroupI/MiniTwit/blob/main/docs/SLA.md} are based on postman and our monitoring dashboard. 





\subsection{Software Quality}



Static code analysis (the linting pipeline)

SonarQube through SonarCloud 

Code Climate

Terms we could use: SDLC, Technical debt


\subsection{Reflection (All)}

Also reflect and describe what was the "DevOps" style of your work. For example, what did you do differently to previous development projects and how did it work?


\subsubsection{THE SECTION BELOW IS JUST FOR NOTING DOWN REFLECTIONS, NEEDS TO BE REWRITTEN}
\begin{itemize}
    \item Our branch strategy of having to review each others PRs for knowledge sharing and keeping a high code quality quickly became somewhat useless as we worked on a lot of new technologies with no prior experience, so it was hard to tell if something was inaccurate. 
    \item Optimally we should have a test environment as well as an production environment, as some changes were hard to test locally and we just pushed strait to production and sometimes caused the application to go down.
    \item We waited until the CI lecture to fully implement testing, meaning that all our deployments were based on educated guesses, meaning that things which worked locally often failed in production. Additionally, we also didn't have CD until the same period, which resulted in weekly releases that failed most of the time. That required us to go through all changes made since the last release and bugfixing them.
\end{itemize}
 

\subsection{Hand over}

We consider that no further maintenance is required. If a new group were to inherit our codebase we have created a document to guide them TODO. 

\section{Conclusion (All)}

Answer the question: Is what we've achieved DevOps?


\input{appendix}


\end{document}



